{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee0882c3",
   "metadata": {},
   "source": [
    "# Ablation Testing\n",
    "\n",
    "This notebook analyzes and compares different chunking parameter combinations for the Readiscoverers backend. It tests various chunking strategies by:\n",
    "\n",
    "1. **Loading test questions** from a shared Google Drive resource (Wizard of Oz questions)\n",
    "2. **Running parameter combination tests** against the local backend API (see `README.md` on how to get started)\n",
    "3. **Comparing results** between the model's performance and expected baseline data\n",
    "4. **Evaluating chunk matching accuracy** using distance metrics (chunk and chapter distances)\n",
    "5. **Analyzing semantic similarity vs chunk size consistency** tradeoffs\n",
    "\n",
    "### Setup Requirements\n",
    "\n",
    "**Important:** You need to obtain your own `client_secrets.json` file from Google Cloud Console and place it in the current directory (`/notebooks/`) to authenticate with Google Drive. This is required to pull the latest `oz_questions.csv` file, which is a shared resource that we always want to be up-to-date when testing.\n",
    "\n",
    "Additionally, ensure your local backend is running before executing the test cells:\n",
    "```bash\n",
    "docker compose up --build\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "935cd00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utils.config import BOOK_URLS, DEV_PARAM_COMBOS, TEST_PARAM_COMBOS\n",
    "from utils.pipeline_readiscovers_app import run_all_tests\n",
    "from utils.pipeline_oz_extractor import preprocess_oz_extractor_results\n",
    "from utils.pipeline_merge import merge_model_and_expected_data\n",
    "from utils.chunk_matching import precompute_text_locations_in_chunks, normalize_text\n",
    "\n",
    "filepath = \"oz_questions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d81949b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from pydrive2.auth import GoogleAuth\n",
    "from pydrive2.drive import GoogleDrive\n",
    "\n",
    "gauth = GoogleAuth();\n",
    "gauth.LoadClientConfigFile(\"client_secrets.json\");\n",
    "gauth.LocalWebserverAuth();\n",
    "\n",
    "drive = GoogleDrive(gauth);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1561747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing existing file: oz_questions.csv\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(filepath):\n",
    "    os.remove(filepath)\n",
    "    print(f\"Replacing existing file: {filepath}\")\n",
    "    time.sleep(1)\n",
    "\n",
    "file = drive.CreateFile({\"id\": \"1aa61xgSOBXu6qH1chEiFqUxgFmBNyvr4Q5bSCFUOkt8\"})\n",
    "file.GetContentFile(filepath, mimetype=\"text/csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62a8546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oz_q_df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ae6ae5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Book #</th>\n",
       "      <th>Book Title</th>\n",
       "      <th>Best Answer</th>\n",
       "      <th>length</th>\n",
       "      <th>Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What color are Dorothy's shoes?</td>\n",
       "      <td>1</td>\n",
       "      <td>The Wonderful Wizard of Oz</td>\n",
       "      <td>“She was so old,” explained the Witch of the N...</td>\n",
       "      <td>285.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How old is the Scarecrow when Dorothy finds him?</td>\n",
       "      <td>1</td>\n",
       "      <td>The Wonderful Wizard of Oz</td>\n",
       "      <td>“My life has been so short that I really know ...</td>\n",
       "      <td>412.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which are the first antagonistic creatures the...</td>\n",
       "      <td>1</td>\n",
       "      <td>The Wonderful Wizard of Oz</td>\n",
       "      <td>In the morning they traveled on until they cam...</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When is the first time we read \"There's no pla...</td>\n",
       "      <td>1</td>\n",
       "      <td>The Wonderful Wizard of Oz</td>\n",
       "      <td>“That is because you have no brains” answered ...</td>\n",
       "      <td>236.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the wizard's secret in the Wonderful W...</td>\n",
       "      <td>1</td>\n",
       "      <td>The Wonderful Wizard of Oz</td>\n",
       "      <td>“No, you are all wrong,” said the little man m...</td>\n",
       "      <td>546.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  Book #  \\\n",
       "0                    What color are Dorothy's shoes?       1   \n",
       "1   How old is the Scarecrow when Dorothy finds him?       1   \n",
       "2  Which are the first antagonistic creatures the...       1   \n",
       "3  When is the first time we read \"There's no pla...       1   \n",
       "4  What is the wizard's secret in the Wonderful W...       1   \n",
       "\n",
       "                   Book Title  \\\n",
       "0  The Wonderful Wizard of Oz   \n",
       "1  The Wonderful Wizard of Oz   \n",
       "2  The Wonderful Wizard of Oz   \n",
       "3  The Wonderful Wizard of Oz   \n",
       "4  The Wonderful Wizard of Oz   \n",
       "\n",
       "                                         Best Answer  length Note  \n",
       "0  “She was so old,” explained the Witch of the N...   285.0  NaN  \n",
       "1  “My life has been so short that I really know ...   412.0  NaN  \n",
       "2  In the morning they traveled on until they cam...  1085.0  NaN  \n",
       "3  “That is because you have no brains” answered ...   236.0  NaN  \n",
       "4  “No, you are all wrong,” said the little man m...   546.0  NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oz_q_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df7bf8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 16 questions from books (2 per book)\n",
      "Selected 4 additional random questions\n",
      "Total: 20 questions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def select_questions(\n",
    "    oz_q_df, random_seed=42, questions_per_book=2, additional_random_questions=4\n",
    "):\n",
    "    # Set random seed for reproducibility\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    # Get unique books\n",
    "    unique_books = oz_q_df[\"Book #\"].unique()\n",
    "\n",
    "    # Select 2 questions from each book\n",
    "    selected_per_book = []\n",
    "    for book_num in unique_books:\n",
    "        book_questions = oz_q_df[oz_q_df[\"Book #\"] == book_num]\n",
    "        sample = book_questions.sample(\n",
    "            n=min(questions_per_book, len(book_questions)), random_state=random_seed\n",
    "        )\n",
    "        selected_per_book.append(sample)\n",
    "\n",
    "    selected_from_books = pd.concat(selected_per_book)\n",
    "\n",
    "    # Select 4 additional random questions from remaining questions\n",
    "    remaining_questions = oz_q_df[~oz_q_df.index.isin(selected_from_books.index)]\n",
    "    additional_questions = remaining_questions.sample(\n",
    "        n=min(additional_random_questions, len(remaining_questions)),\n",
    "        random_state=random_seed,\n",
    "    )\n",
    "\n",
    "    # Combine all selected questions\n",
    "    final_selection = pd.concat([selected_from_books, additional_questions])\n",
    "\n",
    "    print(\n",
    "        f\"Selected {len(selected_from_books)} questions from books ({questions_per_book} per book)\"\n",
    "    )\n",
    "    print(f\"Selected {len(additional_questions)} additional random questions\")\n",
    "    print(f\"Total: {len(final_selection)} questions\\n\")\n",
    "\n",
    "    return final_selection\n",
    "\n",
    "\n",
    "selected_questions_dev = select_questions(oz_q_df)\n",
    "selected_questions_test = oz_q_df[~oz_q_df.index.isin(selected_questions_dev.index)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffa5309",
   "metadata": {},
   "source": [
    "#### IMPORTANT\n",
    "\n",
    "Start up your backend locally for testing\n",
    "\n",
    "> run docker compose up --build\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5bb25b",
   "metadata": {},
   "source": [
    "This test will run through all development parameter combinations for all selected development questions.\n",
    "\n",
    "> In case the API timesout or kills, the results are continously save to results_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947791a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "readiscovers_app_results_df = await run_all_tests(\n",
    "    selected_questions=selected_questions_dev,\n",
    "    param_combos=DEV_PARAM_COMBOS,\n",
    "    book_urls=BOOK_URLS,\n",
    "    skip_book_processing=False,\n",
    "    results_filename=\"readiscovers_app_results_top_3_param_combos_RUN_5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cced79",
   "metadata": {},
   "source": [
    "This test will run through all test parameter combinations for all selected test questions.\n",
    "\n",
    "> In case the API timesout or kills, the results are continously save to results_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "readiscovers_app_results_test_df = await run_all_tests(\n",
    "    selected_questions=selected_questions_test,\n",
    "    param_combos=TEST_PARAM_COMBOS,\n",
    "    book_urls=BOOK_URLS,\n",
    "    skip_book_processing=False,\n",
    "    results_filename=\"readiscovers_app_results_test_param_combos_RUN_2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31520ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_num in readiscovers_app_results_df[\"test_number\"].unique():\n",
    "    test_sorted_df = readiscovers_app_results_df[\n",
    "        readiscovers_app_results_df[\"test_number\"] == test_num\n",
    "    ]\n",
    "    print(\n",
    "        \"Number of results where at least one result is within 1 chunks of the expected answer:\",\n",
    "        test_sorted_df[\n",
    "            test_sorted_df[\"chunk_distance_from_expected\"].apply(\n",
    "                lambda x: isinstance(x, (int, float)) and x <= 1\n",
    "            )\n",
    "        ][\"question_number\"].nunique(),\n",
    "    )\n",
    "    print(\n",
    "        \"Number of results where at least one result is within 3 chunks of the expected answer:\",\n",
    "        test_sorted_df[\n",
    "            test_sorted_df[\"chunk_distance_from_expected\"].apply(\n",
    "                lambda x: isinstance(x, (int, float)) and x <= 3\n",
    "            )\n",
    "        ][\"question_number\"].nunique(),\n",
    "    )\n",
    "    print(\"\")\n",
    "\n",
    "readiscovers_app_results_df[(readiscovers_app_results_df['test_number'] == 1)][['test_number', 'original_query', 'enhanced_query',\n",
    "                             'result_rank', 'matched_book_title', 'expected_book_title',\n",
    "                             'matched_chunk_index', 'chunk_distance_from_expected','expected_all_chunk_indices']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c20993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Number of results where at least one result is within 0 chapter of the expected answer:\",\n",
    "    readiscovers_app_results_df[\n",
    "        readiscovers_app_results_df[\"chapter_distance_from_expected\"].apply(\n",
    "            lambda x: isinstance(x, (int, float)) and x <= 0\n",
    "        )\n",
    "    ][\"question_number\"].nunique(),\n",
    ")\n",
    "readiscovers_app_results_df[\n",
    "    readiscovers_app_results_df[\"chapter_distance_from_expected\"].apply(\n",
    "        lambda x: isinstance(x, (int, float)) and x <= 0\n",
    "    )\n",
    "][\n",
    "    [\n",
    "        \"original_query\",\n",
    "        \"result_rank\",\n",
    "        \"matched_chunk_index\",\n",
    "        \"expected_primary_chunk_index\",\n",
    "        \"expected_all_chunk_indices\",\n",
    "        \"chapter_distance_from_expected\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bf82fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force reload the module\n",
    "import importlib\n",
    "import utils.chunk_matching\n",
    "importlib.reload(utils.chunk_matching)\n",
    "from utils.chunk_matching import precompute_text_locations_in_chunks, normalize_text\n",
    "\n",
    "oz_extractor_results_df = pd.read_csv(\n",
    "    \"oz_extractor_5.1_1_is_match_results.csv\",\n",
    "    usecols=[\n",
    "        \"question\",\n",
    "        \"excerpt_1\",\n",
    "        \"loc_1\",\n",
    "        \"excerpt_2\",\n",
    "        \"loc_2\",\n",
    "        \"excerpt_3\",\n",
    "        \"loc_3\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "oz_extractor_results_df = preprocess_oz_extractor_results(oz_extractor_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dcb7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "oz_extractor_results_df = precompute_text_locations_in_chunks(\n",
    "    oz_extractor_results_df, use_expected_settings=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79def935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug\n",
    "q_row = oz_extractor_results_df.iloc[192]  # Use iloc instead of filtering by question_number\n",
    "test_excerpt = q_row['excerpt']\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"DEBUGGING ROW AT INDEX 192 (Question #{q_row['question_number']})\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Excerpt text: {test_excerpt[:200]}...\")\n",
    "print(f\"\\nNormalized: {normalize_text(test_excerpt)[:200]}...\")\n",
    "\n",
    "# Check which pickle files exist\n",
    "import glob\n",
    "pickle_files = glob.glob(\"../temp/*.pkl\")\n",
    "print(f\"\\nAvailable pickle files: {[os.path.basename(f) for f in pickle_files]}\")\n",
    "\n",
    "# Manually run the search with debug output\n",
    "from utils.chunk_matching import find_chunk_locations_with_continuity\n",
    "\n",
    "for pickle_path in pickle_files:\n",
    "    print(f\"\\n--- Searching in {os.path.basename(pickle_path)} ---\")\n",
    "    result = find_chunk_locations_with_continuity(pickle_path, test_excerpt)\n",
    "    if result:\n",
    "        print(f\"FOUND! Result: {result}\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Not found in this file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b6f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "oz_extractor_results_df.to_csv(\n",
    "    \"oz_extractor_5.1_1_is_match_results_CONT_CHECKED_1.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afea2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "oz_extractor_results_df = pd.read_csv(\"full_continuous_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0876f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results_df = merge_model_and_expected_data(\n",
    "    oz_extractor_results_df, readiscovers_app_results_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f8352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(combined_results_df['question'].to_list()) ^ set(selected_questions['Question'].str.strip().to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1019689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count questions with at least one correct match\n",
    "questions_with_correct_match = combined_results_df[\n",
    "    combined_results_df[\"correct_match\"] == True\n",
    "][\"question\"].nunique()\n",
    "\n",
    "# Total questions\n",
    "total_questions = combined_results_df[\"question\"].nunique()\n",
    "\n",
    "# Calculate percentage\n",
    "percentage = (questions_with_correct_match / total_questions) * 100\n",
    "\n",
    "print(f\"Total unique questions: {total_questions}\")\n",
    "print(f\"Questions with at least one correct match: {questions_with_correct_match}\")\n",
    "print(\n",
    "    f\"Questions without any correct match: {total_questions - questions_with_correct_match}\"\n",
    ")\n",
    "print(f\"Correct match rate: {percentage:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a03e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total unique questions in the dataset\n",
    "total_questions = oz_extractor_results_df[\"question_number\"].nunique()\n",
    "\n",
    "# Questions with at least one match\n",
    "num_questions_with_match = oz_extractor_results_df[\n",
    "    oz_extractor_results_df[\"model_chunk_index\"].notnull()\n",
    "][\"question_number\"].nunique()\n",
    "\n",
    "# Calculate percentage\n",
    "percentage = (num_questions_with_match / total_questions) * 100\n",
    "\n",
    "print(f\"Total unique questions: {total_questions}\")\n",
    "print(f\"Questions with at least one match: {num_questions_with_match}\")\n",
    "print(f\"Questions without any match: {total_questions - num_questions_with_match}\")\n",
    "print(f\"Match rate: {percentage:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
